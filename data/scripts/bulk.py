import subprocess
import json
import os


scripts = [
    "aws/aws.py",
    "azure/azure.py",
    "gcp/get_gcp.py",
    "digitalOcean/do.py",
    "oci/oci.py",
]

def run_script(script_path):
    print(f"\nğŸš€ æ­£åœ¨æ‰§è¡Œ: {script_path}")
    try:
        subprocess.run(["python3", script_path], check=True)
        print(f"âœ… å®Œæˆ: {script_path}")
    except subprocess.CalledProcessError as e:
        print(f"âŒ å¤±è´¥: {script_path}\né”™è¯¯ä¿¡æ¯: {e}")

def download(url):
    try:
        result = subprocess.run(["curl", "-sL", url], check=True, stdout=subprocess.PIPE)
        return result.stdout.decode()
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {url}")
        return None

def save_lines_to_file(lines, filepath):
    with open(filepath, "w", encoding="utf-8") as f:
        for line in sorted(lines):
            f.write(line.strip() + "\n")
    print(f"âœ… å†™å…¥ {len(lines)} æ¡è®°å½•åˆ° {filepath}")

# å¤„ç† Akamai IPv4 + IPv6 txt åˆå¹¶
def process_akamai():
    urls = [
        "https://raw.githubusercontent.com/femueller/cloud-ip-ranges/refs/heads/master/akamai-v4-ip-ranges.txt",
        "https://raw.githubusercontent.com/femueller/cloud-ip-ranges/refs/heads/master/akamai-v6-ip-ranges.txt"
    ]
    all_lines = set()
    for url in urls:
        content = download(url)
        if content:
            for line in content.strip().splitlines():
                line = line.strip()
                if line and not line.startswith("#"):
                    all_lines.add(line)
    save_lines_to_file(all_lines, "akamai.txt")

# å¤„ç† Apple iCloud Private Relay CSV
def process_apple():
    url = "https://raw.githubusercontent.com/femueller/cloud-ip-ranges/refs/heads/master/apple-icloud-private-relay-ip-ranges.csv"
    content = download(url)
    if not content:
        return
    lines = set()
    for line in content.strip().splitlines():
        line = line.strip()
        if line and not line.startswith("#"):
            cidr = line.split(",", 1)[0]
            lines.add(cidr)
    save_lines_to_file(lines, "apple.txt")

# å¤„ç† Linode geofeed æ–‡ä»¶ï¼ˆRFC8805ï¼‰
def process_linode():
    url = "https://raw.githubusercontent.com/femueller/cloud-ip-ranges/refs/heads/master/linode.txt"
    content = download(url)
    if not content:
        return
    lines = set()
    for line in content.strip().splitlines():
        line = line.strip()
        if line and not line.startswith("#"):
            cidr = line.split(",", 1)[0]
            lines.add(cidr)
    save_lines_to_file(lines, "linode.txt")

# å¤„ç† Zscaler JSON æ–‡ä»¶
def process_zscaler():
    url = "https://raw.githubusercontent.com/femueller/cloud-ip-ranges/refs/heads/master/zscaler-cloud-ip-ranges.json"
    content = download(url)
    if not content:
        return
    try:
        data = json.loads(content)
        cidrs = set(data.get("hubPrefixes", []))
        save_lines_to_file(cidrs, "zscaler.txt")
    except json.JSONDecodeError as e:
        print("âŒ è§£æ Zscaler JSON å¤±è´¥")

def main():
    for script in scripts:
        if os.path.exists(script):
            run_script(script)
        else:
            print(f"âš ï¸ è·³è¿‡: {script} æ–‡ä»¶ä¸å­˜åœ¨")
    print("\nğŸ‰ æ‰€æœ‰è„šæœ¬æ‰§è¡Œå®Œæˆï¼")

    os.makedirs("output", exist_ok=True)
    os.chdir("output")
    process_akamai()
    process_apple()
    process_linode()
    process_zscaler()
    print("\nğŸ‰ æ‰€æœ‰æ•°æ®åŒæ­¥å®Œæˆï¼")

if __name__ == "__main__":
    main()
